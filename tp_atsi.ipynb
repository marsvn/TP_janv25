{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ9eCQWtUtgg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from interfile import Interfile as Interfile\n",
        "from PETLibs import *\n",
        "import PETLibs\n",
        "import numpy as np\n",
        "from argparse import ArgumentParser\n",
        "from torch.nn import functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.autonotebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from proj_utils import preprocess_data, postprocess_data, GPU_log_likelihood, GPUBiographProxRecons, GPUBiographEMRecons\n",
        "from IR_utils import prox_TV_L1\n",
        "print(\"hello\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/marsvn/TP_janv25.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Komfk-MpUwm7",
        "outputId": "40d9159d-3015-43e7-cea5-f1273f48cd76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TP_janv25'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37 (from 1)\u001b[K\n",
            "Receiving objects: 100% (37/37), 68.76 MiB | 11.64 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Updating files: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip TP_janv25/lib/interfile.zip -d /content"
      ],
      "metadata": {
        "id": "4l2hnHQFaBAL",
        "outputId": "8443b273-a97d-438d-e598-103c9193101b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  TP_janv25/lib/interfile.zip\n",
            "replace /content/interfile/MANIFEST.in? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e /content/interfile"
      ],
      "metadata": {
        "id": "FFKd3Q7gacey",
        "outputId": "80a01361-5a0d-4f19-9291-dab26be83364",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/interfile\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: interfile\n",
            "  Running setup.py develop for interfile\n",
            "Successfully installed interfile-0.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "56Yv_xnib3V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from interfile.interfile import Interfile as Interfile\n"
      ],
      "metadata": {
        "id": "vs9jEuDlaRDK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip TP_janv25/lib/pyPETLibs.zip -d /content"
      ],
      "metadata": {
        "id": "PTWyxJosb4JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an1eIrICUtgh"
      },
      "source": [
        "Set the scanner configuration and reconstruction grid options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3GaBvkBUtgi"
      },
      "outputs": [],
      "source": [
        "XYZ=True\n",
        "dim_vol = [128,128,109] #number of voxels in final numpy image (in XYZ convention if XYZ is true)\n",
        "vox_size=[2.03642,2.03642,2.027] #voxel size in final numpy image (in XYZ convention if XYZ is true)\n",
        "\n",
        "ParamsGPUEM=PETLibs.recons.GPUBiographReconsParams(lut_name=\"PET_SIEMENS_BIOGRAPH6_TRUEPOINT_TRUEV.lut\",\n",
        "                                    vox_size=vox_size,im_dim=dim_vol,nit=8, verbose=False,nsubsets=14,VRing=True,XYZ=XYZ, deviceGPU=\"cuda:0\") #,fwhm_mm = 4, nbsigmas = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRo4amGGUtgj"
      },
      "source": [
        "Load simulated low dose data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTD12Rd_Utgk"
      },
      "outputs": [],
      "source": [
        "dose_reduc = 5.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCllH3AvUtgk"
      },
      "outputs": [],
      "source": [
        "castor_df_hdr=f\"realizationj00414-1.cdh\"\n",
        "castor_df_dir=\"data_TP/j00414/realizationj00414-1\"\n",
        "\n",
        "\n",
        "castor_df_hdr_fpath=os.path.join(castor_df_dir,castor_df_hdr)\n",
        "dict_sino=PETLibs.recons.GPURecons.GPUCASToRSinos(castor_df_hdr_fpath, castor_df_dir, reconsParams=ParamsGPUEM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXjlcoZ3Utgl"
      },
      "source": [
        "Load corresponding simulated high dose OSEM reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1GuOaVqUtgl"
      },
      "outputs": [],
      "source": [
        "ordose_hdr=Interfile.load(\"data_TP/j00414/originaldose-red-j00414-1-8it-14sub.hdr\")\n",
        "ordose_hdr['name of data file']['value']=\"originaldose-red-j00414-1-8it-14sub.ima\"\n",
        "ordose,_,_,_,_=PETLibs.ios.getNPArrayFromCASToRInterfileHeader(ordose_hdr,\"data_TP/j00414\",verbose=False)\n",
        "\n",
        "\n",
        "xtrue = ordose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlNY66DtUtgl"
      },
      "source": [
        "**Goal for this lab session**: reconstruction images with a \"high-dose iamge quality\" from low-dose data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob_WlM0nUtgm"
      },
      "source": [
        "# Part I: ADMM reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "464R6mrKUtgm"
      },
      "source": [
        "A common way of reconstructing a 3D image $\\overline{x}$ from the set of sinograms $y$ is to estimate $\\overline{x}$ by the minimizer $\\hat{x}$ of\n",
        "\n",
        "$$\n",
        " L(x) + \\lambda g(D x) \\qquad  (P)\n",
        "$$\n",
        "\n",
        "Usually, $g$ is chosen as an $\\ell_1$ norm and $D$ typically refer to a wavelet transform or the gradient operator. In the latter, the regularization is called **total variation**.\n",
        "\n",
        "\n",
        "For Problem (P), the alternating direction method of multipliers (ADMM) writes as\n",
        "\n",
        "$x^{(k+1)} = \\rm{prox}_{L/\\rho}(z^{(k)}+u^{(k)})$\n",
        "\n",
        "$z^{(k+1)} = \\rm{prox}_{\\lambda g(D \\cdot)/\\rho}(x^{(k+1)}  -u^{(k)})$\n",
        "\n",
        "$u^{(k+1)}=u^{(k)} + x^{(k+1)} -  z^{(k+1)}$\n",
        "\n",
        "where $\\rho>0$.\n",
        "\n",
        "The sequences of iterates $(x_k)_k$ and $(z_k)_k$ converge to $\\hat{x}$.\n",
        "\n",
        "Below is the template of an implementation of ADMM for solving (P). Complete it and study the impact of $\\lambda$ and $\\rho$ on image quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f48hQ15Utgm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def admm(x0, nit_admm, reg_par, pnlt_beta, BiographParams, dict_sino):\n",
        "\n",
        "#     v=torch.tensor(np.zeros_like(x0), dtype=torch.float32,device=\"cuda\")\n",
        "#     u=torch.zeros_like(v)\n",
        "\n",
        "#     for _ in range(nit_admm):\n",
        "\n",
        "\n",
        "#         ...\n",
        "#         x=GPUBiographProxRecons(BiographReconsParams=BiographParams,xprox=...,pnlt_beta=pnlt_beta,dict_sino=dict_sino, tensor_output = True)\n",
        "#         ...\n",
        "\n",
        "\n",
        "\n",
        "#     return x\n",
        "\n",
        "\n",
        "\n",
        "def admm(x0, nit_admm, reg_par, pnlt_beta, BiographParams, dict_sino):\n",
        "\n",
        "    v=torch.tensor(np.zeros_like(x0), dtype=torch.float32,device=\"cuda:0\")\n",
        "    u=torch.zeros_like(v, device=\"cuda:0\")\n",
        "\n",
        "    for _ in range(nit_admm):\n",
        "\n",
        "\n",
        "        x=GPUBiographProxRecons(BiographReconsParams=BiographParams,xprox=v-u,pnlt_beta=pnlt_beta,dict_sino=dict_sino, tensor_output = True).squeeze()\n",
        "        n_image=preprocess_data(x+u, tensorFlag=True)\n",
        "        v = prox_TV_L1(n_image, lamb=reg_par/pnlt_beta, maxit=1000,check=100, verbose=0)\n",
        "        v=postprocess_data(v, tensorFlag=True)\n",
        "\n",
        "        u = u + x - v\n",
        "\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEvNw-mZUtgm"
      },
      "outputs": [],
      "source": [
        "nit_admm = 10\n",
        "rho = 1e-6\n",
        "lbd = 0.00002\n",
        "\n",
        "x_admm = admm(x0=ordose, nit_admm=nit_admm, reg_par=lbd, pnlt_beta=rho, BiographParams=ParamsGPUEM, dict_sino=dict_sino)\n",
        "x_admm = x_admm.squeeze().cpu().detach().numpy()\n",
        "\n",
        "fig=PETLibs.utils.display3D_1cbar(x_admm,interpolation='none', vmin = 0, vmax= 2600, title='reconstruction with ADMM - TV regularization')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wExzDe3JUtgn"
      },
      "source": [
        "# Part II: Proximity operator vs denoiser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaZrd03FUtgn"
      },
      "source": [
        "Reconstruct the low-dose data using OSEM with 8 iterations and 14 subsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EADeY2hXUtgn"
      },
      "outputs": [],
      "source": [
        "ParamsGPUEM=PETLibs.recons.GPUBiographReconsParams(lut_name=\"PET_SIEMENS_BIOGRAPH6_TRUEPOINT_TRUEV.lut\",\n",
        "                                    vox_size=vox_size,im_dim=dim_vol,nit=10, verbose=False,nsubsets=14,VRing=True,XYZ=XYZ,deviceGPU=\"cuda:0\")\n",
        "\n",
        "\n",
        "recon_EM_LD = GPUBiographEMRecons(castor_df_hdr_fpath, castor_df_dir,reconsParams=ParamsGPUEM, dict_sino=dict_sino, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me5TAtgUUtgo"
      },
      "source": [
        "Display the high-dose reference and low-dose OSEM reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8ns77nLUtgp"
      },
      "outputs": [],
      "source": [
        "fig=PETLibs.utils.display3D_1cbar(ordose,interpolation='none', vmin = 0, vmax= 2600, title=\"high dose reference\")\n",
        "fig=PETLibs.utils.display3D_1cbar(recon_EM_LD,interpolation='none', vmin = 0, vmax= 2600, title=\"OSEM low dose\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFigruBGUtgp"
      },
      "source": [
        "Apply different post-reconstruction denoisers on the OSEM low dose image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZSnUpg8Utgp"
      },
      "outputs": [],
      "source": [
        "xnoisy = recon_EM_LD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U-lbuYJUtgp"
      },
      "source": [
        "### Post reconstruction denoiser: TV prox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxHDHHxHUtgp"
      },
      "outputs": [],
      "source": [
        "from IR_utils import prox_TV_L1\n",
        "\n",
        "reg_par = 250\n",
        "x_noisy = preprocess_data(xnoisy)\n",
        "xtv = prox_TV_L1(x_noisy, lamb=reg_par, maxit=1000)\n",
        "xtv = postprocess_data(xtv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR5V8eagUtgq"
      },
      "source": [
        "### Post reconstruction denoiser: gaussian filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHraUsFZUtgq"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numbers\n",
        "\n",
        "\n",
        "class GaussianSmoothing(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply gaussian smoothing on a\n",
        "    1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n",
        "    in the input using a depthwise convolution.\n",
        "    Arguments:\n",
        "        channels (int, sequence): Number of channels of the input tensors. Output will\n",
        "            have this number of channels as well.\n",
        "        kernel_size (int, sequence): Size of the gaussian kernel.\n",
        "        sigma (float, sequence): Standard deviation of the gaussian kernel.\n",
        "        dim (int, optional): The number of dimensions of the data.\n",
        "            Default value is 2 (spatial).\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, kernel_size, sigma, dim=2):\n",
        "        super(GaussianSmoothing, self).__init__()\n",
        "        if isinstance(kernel_size, numbers.Number):\n",
        "            kernel_size = [kernel_size] * dim\n",
        "        if isinstance(sigma, numbers.Number):\n",
        "            sigma = [sigma] * dim\n",
        "            #you should smooth with a Gaussian filter approximately three times the size of your voxel.\n",
        "\n",
        "        # The gaussian kernel is the product of the\n",
        "        # gaussian function of each dimension.\n",
        "        kernel = 1\n",
        "        meshgrids = torch.meshgrid(\n",
        "            [\n",
        "                torch.arange(size, dtype=torch.float32)\n",
        "                for size in kernel_size\n",
        "            ]\n",
        "        )\n",
        "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
        "            mean = (size - 1) / 2\n",
        "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
        "                      torch.exp(-((mgrid - mean) / std) ** 2 / 2)\n",
        "\n",
        "        # Make sure sum of values in gaussian kernel equals 1.\n",
        "        kernel = kernel / torch.sum(kernel)\n",
        "\n",
        "        # Reshape to depthwise convolutional weight\n",
        "        kernel = kernel.view(1, 1, *kernel.size())\n",
        "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
        "\n",
        "        self.register_buffer('weight', kernel)\n",
        "        self.groups = channels\n",
        "\n",
        "        if dim == 1:\n",
        "            self.conv = F.conv1d\n",
        "        elif dim == 2:\n",
        "            self.conv = F.conv2d\n",
        "        elif dim == 3:\n",
        "            self.conv = F.conv3d\n",
        "        else:\n",
        "            raise RuntimeError(\n",
        "                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Apply gaussian filter to input.\n",
        "        Arguments:\n",
        "            input (torch.Tensor): Input to apply gaussian filter on.\n",
        "        Returns:\n",
        "            filtered (torch.Tensor): Filtered output.\n",
        "        \"\"\"\n",
        "        return self.conv(input, weight=self.weight, groups=self.groups, padding=2)\n",
        "\n",
        "\n",
        "\n",
        "def sigma2fwhm(sigma):\n",
        "     return sigma * np.sqrt(8 * np.log(2))\n",
        "\n",
        "\n",
        "def fwhm2sigma(fwhm):\n",
        "    return fwhm / np.sqrt(8 * np.log(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mavJhjjiUtgq"
      },
      "outputs": [],
      "source": [
        "kernel_size = 5\n",
        "fwhm = 1.5\n",
        "sigma_gaussian = fwhm2sigma(fwhm)\n",
        "x_noisy = preprocess_data(xnoisy)\n",
        "smoothing = GaussianSmoothing(1, kernel_size, sigma_gaussian, 3).cuda()\n",
        "xgauss = postprocess_data(smoothing(x_noisy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRjw0AZPUtgr"
      },
      "source": [
        "### Post reconstruction denoiser: BM3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz_jKXNKUtgr"
      },
      "outputs": [],
      "source": [
        "import bm4d\n",
        "reg_par = 700\n",
        "xbm3d_2=bm4d.bm4d(xnoisy.squeeze(), reg_par)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGFZNUZZUtgr"
      },
      "source": [
        "### Post reconstruction deep denoisers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46ZO5NVZUtgr"
      },
      "outputs": [],
      "source": [
        "from DL_utils import MyDenoiser, MyLDenoiser\n",
        "\n",
        "net0 = MyLDenoiser()\n",
        "net1 = MyDenoiser()\n",
        "net2 = MyDenoiser()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():  # Move to GPU if possible\n",
        "    net0 = net0.cuda()\n",
        "    net1 = net1.cuda()\n",
        "    net2 = net2.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEG9X_5UUtgr"
      },
      "source": [
        "Loading net1 and net 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-TeFbzTUtgs"
      },
      "outputs": [],
      "source": [
        "filename = './net0.ckpt'\n",
        "checkpoint = torch.load(filename)\n",
        "net0.load_state_dict(checkpoint['state_dict'], strict=True)\n",
        "net0.eval()\n",
        "\n",
        "\n",
        "filename = './net2.ckpt'\n",
        "checkpoint = torch.load(filename)\n",
        "net2.load_state_dict(checkpoint['state_dict'], strict=True)\n",
        "net2.eval()\n",
        "\n",
        "filename = 'net1.ckpt'\n",
        "checkpoint = torch.load(filename)\n",
        "net1.load_state_dict(checkpoint['state_dict'], strict=True)\n",
        "net1.eval()\n",
        "net1.cuda()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJpQa8HhUtgs"
      },
      "outputs": [],
      "source": [
        "x_noisy = preprocess_data(xnoisy)\n",
        "xnet0 = postprocess_data(net0(x_noisy))\n",
        "xnet2 = postprocess_data(net2(x_noisy))\n",
        "xnet1 = postprocess_data(net1(x_noisy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5KAnXm-Utgs"
      },
      "source": [
        "Comparing all denoisers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZWtlpiTUtgt"
      },
      "outputs": [],
      "source": [
        "fig=PETLibs.utils.display3D_1cbar(xtrue,interpolation='none', vmin = 0, vmax= 2600, title='Reference')\n",
        "fig=PETLibs.utils.display3D_1cbar(xnoisy,interpolation='none', vmin = 0, vmax= 2600, title='EM')\n",
        "fig=PETLibs.utils.display3D_1cbar(xtv,interpolation='none', vmin = 0, vmax= 2600, title='Denoised with total variation')\n",
        "fig=PETLibs.utils.display3D_1cbar(xgauss,interpolation='none', vmin = 0, vmax= 2600, title='Denoised with Gaussian')\n",
        "fig=PETLibs.utils.display3D_1cbar(xbm3d_2,interpolation='none', vmin = 0, vmax= 2600, title='Denoised with BM3D')\n",
        "fig=PETLibs.utils.display3D_1cbar(xnet0,interpolation='none', vmin = 0, vmax= 2600, title='Denoised with net0')\n",
        "fig=PETLibs.utils.display3D_1cbar(xnet1,interpolation='none', vmin = 0, vmax= 2600, title='Denoised with net1')\n",
        "fig=PETLibs.utils.display3D_1cbar(xnet2,interpolation='none', vmin = 0, vmax= 2600, title='Denoised with net2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rn2GIOUUtgt"
      },
      "source": [
        "TODO: add quantitative metrics (e.g. MSE, MAE, SSIM) using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GqGHc28Utgu"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "compute_MSE = torch.nn.MSELoss()\n",
        "compute_MAE = torchmetrics.MeanAbsoluteError()\n",
        "compute_SS = torchmetrics.StructuralSimilarityIndexMeasure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxaMQrSQUtgu"
      },
      "outputs": [],
      "source": [
        "# comparing the MSE associated with each method\n",
        "criterion = torch.nn.MSELoss()\n",
        "mse_em = criterion(torch.tensor(xnoisy), torch.tensor(xtrue)).item()\n",
        "mse_tv = criterion(torch.tensor(xtv), torch.tensor(xtrue)).item()\n",
        "mse_bm3d = criterion(torch.tensor(xbm3d_2), torch.tensor(xtrue)).item()\n",
        "mse_gauss = criterion(torch.tensor(xgauss), torch.tensor(xtrue)).item()\n",
        "mse_net0 = criterion(torch.tensor(xnet0), torch.tensor(xtrue)).item()\n",
        "mse_net2 = criterion(torch.tensor(xnet2), torch.tensor(xtrue)).item()\n",
        "mse_net1 = criterion(torch.tensor(xnet1), torch.tensor(xtrue)).item()\n",
        "\n",
        "\n",
        "\n",
        "print('MSE EM: ', mse_em)\n",
        "print('MSE TV: ', mse_tv)\n",
        "print('MSE BM3D: ', mse_bm3d)\n",
        "print('MSE Gauss: ', mse_gauss)\n",
        "print('MSE net0: ', mse_net0)\n",
        "print('MSE net1: ', mse_net1)\n",
        "print('MSE net2: ', mse_net2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiF5Rlm5Utgu"
      },
      "source": [
        "TODO: measure execution time of all denoisers using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir0q---KUtgu"
      },
      "outputs": [],
      "source": [
        "import timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkbVyHu2Utgv"
      },
      "source": [
        "# Part III: PnP ADMM with prox surrogate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfRQTJn8Utgv"
      },
      "source": [
        "Edit admm to replace the proximity operator of TV with a deep model (net1 or net2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab0b65_yUtgw"
      },
      "outputs": [],
      "source": [
        "def compute_norm_jac(x, y, tol, max_iter):\n",
        "    '''\n",
        "    Perform evaluation of the spectral radius of the jacobian dy/dx(x)\n",
        "\n",
        "    Arguments:\n",
        "        - x: input where the Jacobian is computed (torch.Tensor).\n",
        "        - y: output of the operator of which the spectral radius of the Jacobian is computed  (torch.Tensor).\n",
        "\n",
        "    Returns:\n",
        "        spectral_radius: last evaluation of spectral radius of Jacobian.\n",
        "        lst_spectral_radius: list of values of spectral radius of Jacobian across iterations.\n",
        "    '''\n",
        "    torch.random.manual_seed(0)\n",
        "    u = torch.randn_like(x)\n",
        "    u = u/torch.matmul(u.reshape(u.shape[0], 1, -1), u.reshape(u.shape[0], -1, 1)).view(u.shape[0], 1, 1, 1)\n",
        "\n",
        "    z_old = torch.zeros(u.shape[0])\n",
        "    with tqdm(total=max_iter, desc=\"Power Method\",leave=False) as pbar_jac:\n",
        "        for it in range(max_iter-1):\n",
        "            w = torch.ones_like(y, requires_grad=True)  # Double backward trick. From https://gist.github.com/apaszke/c7257ac04cb8debb82221764f6d117ad\n",
        "            v = torch.autograd.grad(torch.autograd.grad(y, x, w, create_graph=True), w, u, create_graph=False)[0]  # Ju\n",
        "            w.detach_()\n",
        "            v.detach_()\n",
        "            v = torch.autograd.grad(y, x, v, retain_graph=True, create_graph=False)[0]  # vtJt\n",
        "\n",
        "            z = torch.matmul(u.reshape(u.shape[0], 1, -1), v.reshape(v.shape[0], -1, 1)) / torch.matmul(u.reshape(u.shape[0], 1, -1), u.reshape(u.shape[0], -1, 1))\n",
        "            if it > 0:\n",
        "                rel_var = torch.norm(z-z_old)\n",
        "                if rel_var < tol:\n",
        "                    break\n",
        "            z_old = z.clone()\n",
        "\n",
        "            u = v/torch.matmul(v.reshape(v.shape[0], 1, -1), v.reshape(v.shape[0], -1, 1)).view(v.shape[0], 1, 1, 1)\n",
        "            pbar_jac.update(1)\n",
        "            u.detach_()\n",
        "\n",
        "\n",
        "        pbar_jac.update(1)\n",
        "        w.detach_()\n",
        "        v.detach_()\n",
        "    return z.view(-1).sqrt()\n",
        "\n",
        "def pnp_admm(x0, nit_admm, model, pnlt_beta, max_iter_jacobian, prec, device, BiographParams, dict_sino, target, nb_everyIter_jac = 1):\n",
        "\n",
        "    v=torch.tensor(np.zeros_like(x0), dtype=torch.float32,device=\"cuda\")\n",
        "    u=torch.zeros_like(v)\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    mse = []\n",
        "    log_l = []\n",
        "    norm1 = []\n",
        "    norm2 = []\n",
        "    reg = []\n",
        "    model_run=lambda v: model(v)[0]\n",
        "\n",
        "\n",
        "    for i in range(nit_admm):\n",
        "\n",
        "\n",
        "        # xprox=torch.swapaxes(v-u,2,0)\n",
        "        x=GPUBiographProxRecons(BiographReconsParams=BiographParams,xprox=v-u,pnlt_beta=pnlt_beta,dict_sino=dict_sino, tensor_output = True).squeeze()\n",
        "\n",
        "        # x_ZYX=torch.swapaxes(x,2,0)\n",
        "        loss = criterion(preprocess_data(x, tensorFlag=True), target)\n",
        "        mse.append(loss.item())\n",
        "        l = GPU_log_likelihood(x, eps =0,BiographParams=BiographParams,dict_sino=dict_sino)\n",
        "        log_l.append(l)\n",
        "\n",
        "        v_old = v\n",
        "        n_image=preprocess_data(x+u, tensorFlag=True)\n",
        "        v = model_run(n_image)\n",
        "        v=postprocess_data(v.squeeze(), tensorFlag=True)\n",
        "\n",
        "        out_detached = n_image.detach()\n",
        "        out_detached.requires_grad_()\n",
        "        out_net_reg = 2.*model_run(out_detached)-out_detached\n",
        "        if i%nb_everyIter_jac==0:\n",
        "            reg_loss = compute_norm_jac(out_detached, out_net_reg, tol = 1e-3, max_iter = max_iter_jacobian)\n",
        "            reg_loss = reg_loss.item()\n",
        "            print(\"jac=\", reg_loss)\n",
        "            reg.append(reg_loss)\n",
        "\n",
        "\n",
        "        primalN=torch.linalg.norm(x-v)\n",
        "        dualN=torch.linalg.norm(v-v_old)\n",
        "\n",
        "        if i > 0:\n",
        "            if (dualN/torch.linalg.norm(v)<prec) & (primalN/torch.linalg.norm(v)<prec):\n",
        "                print(\"Convergence reached\")\n",
        "                break\n",
        "\n",
        "            norm1.append(primalN.item())\n",
        "            norm2.append(dualN.item())\n",
        "\n",
        "        u = u + x - v\n",
        "\n",
        "    results={}\n",
        "    results[\"x\"]=x\n",
        "    results[\"mse\"]=mse\n",
        "    results[\"reg\"]=reg\n",
        "    results[\"logl\"]=log_l\n",
        "    results[\"norm1\"]=norm1\n",
        "    results[\"norm2\"]=norm2\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkM6WU8yUtgw"
      },
      "source": [
        "Setting hyperparameters of pnp-admm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0wpRoc3Utgw"
      },
      "outputs": [],
      "source": [
        "max_iter_jacobian = 3\n",
        "device = 'cuda'\n",
        "prec = 1e-3\n",
        "nit_admm = 40\n",
        "pnlt_beta = 1e-7\n",
        "nb_everyIter_jac = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0FTYBqqUtgw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkWyGS_wUtgw"
      },
      "outputs": [],
      "source": [
        "results_admm = pnp_admm(x0=xnoisy, nit_admm=nit_admm, model=net1, pnlt_beta=pnlt_beta, max_iter_jacobian=max_iter_jacobian, prec=prec, device=device, BiographParams=ParamsGPUEM, dict_sino=dict_sino, target=preprocess_data(ordose), nb_everyIter_jac=nb_everyIter_jac)\n",
        "x_admm = results_admm[\"x\"].squeeze().cpu().detach().numpy()\n",
        "mse_admm = results_admm[\"mse\"]\n",
        "reg_admm = results_admm[\"reg\"]\n",
        "logl_admm = results_admm[\"logl\"]\n",
        "norm1_admm = results_admm[\"norm1\"]\n",
        "norm2_admm = results_admm[\"norm2\"]\n",
        "\n",
        "\n",
        "fig=PETLibs.utils.display3D_1cbar(x_admm,interpolation='none', vmin=0, vmax=2600, title='reconstruction with PnP ADMM - net3')\n",
        "\n",
        "#plotting mse as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(mse_admm)\n",
        "plt.title('MSE')\n",
        "plt.show()\n",
        "\n",
        "#plotting log likelihood as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(logl_admm)\n",
        "plt.title('Log likelihood')\n",
        "plt.show()\n",
        "\n",
        "#plotting norm1 as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(norm1_admm)\n",
        "plt.title('Norm1')\n",
        "plt.show()\n",
        "\n",
        "#plotting norm2 as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(norm2_admm)\n",
        "plt.title('Norm2')\n",
        "plt.show()\n",
        "\n",
        "#plotting reg as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(reg_admm)\n",
        "plt.title('Reg')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RsxvRWhUtgx"
      },
      "outputs": [],
      "source": [
        "\n",
        "results_admm2 = pnp_admm(x0=xnoisy, nit_admm=nit_admm, model=net2, pnlt_beta=pnlt_beta, max_iter_jacobian=max_iter_jacobian, prec=prec, device=device, BiographParams=ParamsGPUEM, dict_sino=dict_sino, target=preprocess_data(ordose),nb_everyIter_jac=nb_everyIter_jac)\n",
        "\n",
        "x_admm2 = results_admm2[\"x\"].squeeze().cpu().detach().numpy()\n",
        "mse_admm2 = results_admm2[\"mse\"]\n",
        "reg_admm2 = results_admm2[\"reg\"]\n",
        "logl_admm2 = results_admm2[\"logl\"]\n",
        "norm1_admm2 = results_admm2[\"norm1\"]\n",
        "norm2_admm2 = results_admm2[\"norm2\"]\n",
        "\n",
        "\n",
        "fig=PETLibs.utils.display3D_1cbar(x_admm2,interpolation='none', vmin=0, vmax=2600, title='reconstruction with PnP ADMM - net2')\n",
        "\n",
        "#plotting mse as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(mse_admm2)\n",
        "plt.title('MSE')\n",
        "plt.show()\n",
        "\n",
        "#plotting log likelihood as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(logl_admm2)\n",
        "plt.title('Log likelihood')\n",
        "plt.show()\n",
        "\n",
        "#plotting norm1 as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(norm1_admm2)\n",
        "plt.title('Norm1')\n",
        "plt.show()\n",
        "\n",
        "#plotting norm2 as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(norm2_admm2)\n",
        "plt.title('Norm2')\n",
        "plt.show()\n",
        "\n",
        "#plotting reg as a function of iteration\n",
        "plt.figure()\n",
        "plt.plot(reg_admm2)\n",
        "plt.title('Reg')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_0JfvcPUtgx"
      },
      "source": [
        "The iterates of PnP ADMM converge when the denoiser $D$ is firmly nonexpansive i.e.\n",
        "\n",
        "            2D - I is 1-lipschitz (Lip)\n",
        "\n",
        "            \n",
        "Given that an operator $A$ is L-lipchitz if the spectral norm of its jacobian (or gradient for functions $\\mathbb{R}^N \\mapsto \\mathbb{R}$) is smaller than L.\n",
        "Use the power method (https://math.univ-cotedazur.fr/~frapetti/CorsoF/cours4part2.pdf) to compute the spectral norm of the jacobian of $2D - I$ (denoted $J$).\n",
        "\n",
        "Hint 1: the power method is applicable to symmetric operators so you should use that $||J^T J|| = ||J||^2$.\n",
        "\n",
        "Hint 2: Double backward trick. From https://gist.github.com/apaszke/c7257ac04cb8debb82221764f6d117ad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LkeN2I6Utgx"
      },
      "outputs": [],
      "source": [
        "def compute_norm_jac(x, y, tol, max_iter):\n",
        "    '''\n",
        "    Perform evaluation of the spectral radius of the jacobian dy/dx(x)\n",
        "\n",
        "    Arguments:\n",
        "        - x: input where the Jacobian is computed (torch.Tensor).\n",
        "        - y: output of the operator of which the spectral radius of the Jacobian is computed  (torch.Tensor).\n",
        "    '''\n",
        "    torch.random.manual_seed(0)\n",
        "    u = torch.randn_like(x)\n",
        "    u = u/torch.matmul(u.reshape(u.shape[0], 1, -1), u.reshape(u.shape[0], -1, 1)).view(u.shape[0], 1, 1, 1)\n",
        "\n",
        "    z_old = torch.zeros(u.shape[0])\n",
        "    with tqdm(total=max_iter, desc=\"Power Method\",leave=False) as pbar_jac:\n",
        "        for it in range(max_iter-1):\n",
        "            w = torch.ones_like(y, requires_grad=True)  # Double backward trick. From https://gist.github.com/apaszke/c7257ac04cb8debb82221764f6d117ad\n",
        "            v = torch.autograd.grad(torch.autograd.grad(y, x, w, create_graph=True), w, u, create_graph=False)[0]  # Ju\n",
        "            w.detach_()\n",
        "            v.detach_()\n",
        "            v = torch.autograd.grad(y, x, v, retain_graph=True, create_graph=False)[0]  # vtJt\n",
        "\n",
        "            z = torch.matmul(u.reshape(u.shape[0], 1, -1), v.reshape(v.shape[0], -1, 1)) / torch.matmul(u.reshape(u.shape[0], 1, -1), u.reshape(u.shape[0], -1, 1))\n",
        "            if it > 0:\n",
        "                rel_var = torch.norm(z-z_old)\n",
        "                if rel_var < tol:\n",
        "                    break\n",
        "            z_old = z.clone()\n",
        "\n",
        "            u = v/torch.matmul(v.reshape(v.shape[0], 1, -1), v.reshape(v.shape[0], -1, 1)).view(v.shape[0], 1, 1, 1)\n",
        "            pbar_jac.update(1)\n",
        "            u.detach_()\n",
        "\n",
        "\n",
        "        pbar_jac.update(1)\n",
        "        w.detach_()\n",
        "        v.detach_()\n",
        "    return z.view(-1).sqrt()\n",
        "\n",
        "\n",
        "def func_unknown(y, xref, model, max_iter, eta, lr) :\n",
        "    '''\n",
        "    ?\n",
        "    '''\n",
        "    torch.random.manual_seed(0)\n",
        "    n = torch.rand_like(xref)\n",
        "    n = n/torch.norm(n)*eta\n",
        "    n.requires_grad = True\n",
        "    optimizer = torch.optim.Adam([n], lr=lr)\n",
        "    for i in range(max_iter):\n",
        "        optimizer.zero_grad()\n",
        "        loss = -torch.norm(y.detach() - model(xref.detach() + n))\n",
        "        # print(\"loss\", loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        n.data = n.data/torch.norm(n.data)*eta\n",
        "\n",
        "    return (xref + n).detach(), torch.norm(y.detach() - model(xref.detach() + n)).item()/eta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z6DiQJdUtgy"
      },
      "outputs": [],
      "source": [
        "x_noisy = preprocess_data(xnoisy).detach().requires_grad_()\n",
        "e = net2(x_noisy)-x_noisy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSbroV7RUtgy"
      },
      "source": [
        "Test whether net2 or net3 satisfies the FNE condition on the OSEM image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rneq8nrjUtgz"
      },
      "outputs": [],
      "source": [
        "del x_noisy\n",
        "x_noisy = preprocess_data(xnoisy).detach().requires_grad_()\n",
        "x_noisy = x_noisy\n",
        "_2Dx_x = 2*net2(x_noisy) - x_noisy\n",
        "jac_norm_net2 = compute_norm_jac(x_noisy, _2Dx_x, tol = 1e-3, max_iter = 10).item()\n",
        "print(\"jac net 2 : \",jac_norm_net2)\n",
        "\n",
        "_2Dx_x = 2*net1(x_noisy) - x_noisy\n",
        "jac_norm_net1 = compute_norm_jac(x_noisy, _2Dx_x, tol = 1e-3, max_iter = 10).item()\n",
        "print(\"jac net 1 : \",jac_norm_net1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oivl2MSDUtgz"
      },
      "source": [
        "What is the following function doing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJTpLPT8Utgz"
      },
      "outputs": [],
      "source": [
        "def func_unknown(y, xref, model, max_iter, eta, lr) :\n",
        "    '''\n",
        "    ?\n",
        "    '''\n",
        "    torch.random.manual_seed(0)\n",
        "    n = torch.rand_like(xref)\n",
        "    n = n/torch.norm(n)*eta\n",
        "    n.requires_grad = True\n",
        "    optimizer = torch.optim.Adam([n], lr=lr)\n",
        "    for i in range(max_iter):\n",
        "        optimizer.zero_grad()\n",
        "        loss = -torch.norm(y.detach() - model(xref.detach() + n))\n",
        "        # print(\"loss\", loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        n.data = n.data/torch.norm(n.data)*eta\n",
        "\n",
        "    return (xref + n).detach(), torch.norm(y.detach() - model(xref.detach() + n)).item()/eta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWF09Yt_Utgz"
      },
      "outputs": [],
      "source": [
        "x_noisy = preprocess_data(xnoisy).detach().requires_grad_()\n",
        "\n",
        "x_per, loss = func_unknown(net2(x_noisy), x_noisy, net2, 1000, 2000, 0.002)\n",
        "print(loss)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(x_per),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(x_noisy),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(net2(x_noisy)),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(net2(x_per)),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(net2(x_per)-net2(x_noisy)),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(x_per-x_noisy),interpolation='none', perc=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIvb_5UVUtgz"
      },
      "outputs": [],
      "source": [
        "x_noisy = preprocess_data(xnoisy).detach().requires_grad_()\n",
        "\n",
        "x_per, loss = func_unknown(net1(x_noisy), x_noisy , net1 , 1000, 2000, 0.002)\n",
        "print(loss)\n",
        "\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(x_per),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(x_noisy),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(net1(x_noisy)),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(net1(x_per)),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(net1(x_per)-net1(x_noisy)),interpolation='none', perc=0.7)\n",
        "fig=PETLibs.utils.display3D_1cbar(postprocess_data(x_per-x_noisy),interpolation='none', perc=0.7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfBSFwyRUtgz"
      },
      "source": [
        "### Making an arbitrary denoiser a FNE denoiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svpakjlIUtg0"
      },
      "outputs": [],
      "source": [
        "Lip = 1.0 #replace by jac_norm_net2 or jac_norm_net3\n",
        "net = torch.nn.Identity() #replace by net2 or net3\n",
        "FNE_net = lambda x: (1.0-0.5/Lip)*x+0.5/Lip*net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5ypZgDAUtg0"
      },
      "outputs": [],
      "source": [
        "results_admm_FNE = pnp_admm(x0=xnoisy, nit_admm=30, model=FNE_net, pnlt_beta=pnlt_beta, max_iter_jacobian=2, prec=prec, device=device, BiographParams=ParamsGPUEM, dict_sino=dict_sino, target=preprocess_data(ordose))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk4C844gUtg0"
      },
      "outputs": [],
      "source": [
        "x_admm_FNE = results_admm_FNE[\"x\"].squeeze().cpu().detach().numpy()\n",
        "mse_admm_FNE = results_admm_FNE[\"mse\"]\n",
        "# reg_admm_jac = results_admm_FNE[\"reg\"]\n",
        "logl_admm_FNE = results_admm_FNE[\"logl\"]\n",
        "norm1_admm_FNE = results_admm_FNE[\"norm1\"]\n",
        "norm2_admm_FNE = results_admm_FNE[\"norm2\"]\n",
        "\n",
        "fig=PETLibs.utils.display3D_1cbar(x_admm_FNE,interpolation='none', perc=0.7, title='reconstruction with PnP ADMM FNE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gy_DEAkUtg1"
      },
      "source": [
        "## Generalization of previous results to patient with Alzheimer disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1QKCj0Utg1"
      },
      "outputs": [],
      "source": [
        "\n",
        "castor_df_hdr=f\"realizationj00366-1.cdh\"\n",
        "castor_df_dir=\"data_TP/j00366/realizationj00366-1\"\n",
        "\n",
        "castor_df_hdr_fpath=os.path.join(castor_df_dir,castor_df_hdr)\n",
        "dict_sino=PETLibs.recons.GPURecons.GPUCASToRSinos(castor_df_hdr_fpath, castor_df_dir, reconsParams=ParamsGPUEM)\n",
        "\n",
        "ParamsGPUEM=PETLibs.recons.GPUBiographReconsParams(lut_name=\"PET_SIEMENS_BIOGRAPH6_TRUEPOINT_TRUEV.lut\",\n",
        "                                    vox_size=vox_size,im_dim=dim_vol,nit=10, verbose=False,nsubsets=14,VRing=True,XYZ=XYZ)\n",
        "\n",
        "\n",
        "recon_EM_LD = PETLibs.recons.GPUEMRecons(castor_df_hdr_fpath, castor_df_dir,reconsParams=ParamsGPUEM, dict_sino=dict_sino, verbose=False)\n",
        "\n",
        "ordose_hdr=Interfile.load(\"data_TP/j00366/originaldose-red-j00366-1-10it-14sub.hdr\")\n",
        "ordose_hdr['name of data file']['value']=\"originaldose-red-j00366-1-10it-14sub.ima\"\n",
        "ordose,_,_,_,_=PETLibs.ios.getNPArrayFromCASToRInterfileHeader(ordose_hdr,\"data_TP/j00366\",verbose=False)\n",
        "\n",
        "\n",
        "x_noisy = preprocess_data(recon_EM_LD)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7mW-iqCUtg2"
      },
      "source": [
        "# Part IV: PnP FB with gradient surrogate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nby8YD9RUtg2"
      },
      "source": [
        "GS-net1 is a denoiser that writes as $N(x) + J_{N(x)}^\\top (x - N(x))$.\n",
        "\n",
        "The forward backward algorithm for PET reconstruction (minimize $LL(x) + r(x)$) with $r$ non convex function with lipschitz differentiable gradient writes as\n",
        "$$\n",
        "{x^{k+1}} {= prox_{\\tau LL+ \\iota_{\\left[0,+\\infty\\right[^N}}(x^k -  \\tau \\nabla r(x^k))}\\\\\n",
        "%x^{k+1}_\\lambda = prox_{\\tau LL+ \\iota_{\\left[0,+\\infty\\right[^N}}(\\lambda \\tau {D_{\\theta}}(x^k_\\lambda) + (1-\\lambda \\tau) x^k_\\lambda)$$\n",
        "for $\\tau < 2/L$\n",
        "\n",
        "When $L$ is unknown, a backtracking linesearch can be used to compute the step size $\\tau$.\n",
        "\n",
        "Explore the forward backward algorithm when $r = \\|\\nabla x\\|^2_2$ as implemented below. What could be a PnP version of the FB algorithm where GS-net1 acts as a regularization ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atzIBs0jUtg2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def fb(x0, nit_fb, reg_par, BiographParams, dict_sino):\n",
        "\n",
        "    x=torch.tensor(np.zeros_like(x0), dtype=torch.float32,device=\"cuda\")\n",
        "\n",
        "    # define the finite differences operator\n",
        "\n",
        "    Dh = torch.tensor([[[0., 0., 0.],\n",
        "                        [0., 0., 0.],\n",
        "                        [0., 0., 0.]],\n",
        "                        [[0., 0., 0.],\n",
        "                        [-1, 1., 0.],\n",
        "                        [0., 0., 0.]],\n",
        "                        [[0., 0., 0.],\n",
        "                        [0., 0., 0.],\n",
        "                        [0., 0., 0.]]]).view(1,1,3,3,3).cuda()\n",
        "\n",
        "\n",
        "    Dp = torch.tensor([[[0., 0., 0.],\n",
        "                    [0., -1., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., 1., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., 0., 0.],\n",
        "                    [0., 0., 0.]]]).view(1,1,3,3,3).cuda()\n",
        "\n",
        "    Dv = torch.tensor([[[0., 0., 0.],\n",
        "                    [0., 0., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., -1., 0.],\n",
        "                    [0., 1., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., 0., 0.],\n",
        "                    [0., 0., 0.]]]).view(1,1,3,3,3).cuda()\n",
        "\n",
        "\n",
        "    D = torch.concatenate([Dh, Dp, Dv], dim=0)\n",
        "\n",
        "    # and its adjoint\n",
        "\n",
        "    Dh_star = torch.tensor([[[0., 0., 0.],\n",
        "                        [0., 0., 0.],\n",
        "                        [0., 0., 0.]],\n",
        "                        [[0., 0., 0.],\n",
        "                        [0., 1., -1.],\n",
        "                        [0., 0., 0.]],\n",
        "                        [[0., 0., 0.],\n",
        "                        [0., 0., 0.],\n",
        "                        [0., 0., 0.]]]).view(1,1,3,3,3).cuda()\n",
        "\n",
        "\n",
        "    Dp_star = torch.tensor([[[0., 0., 0.],\n",
        "                    [0., 0., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., 1., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., -1., 0.],\n",
        "                    [0., 0., 0.]]]).view(1,1,3,3,3).cuda()\n",
        "\n",
        "    Dv_star = torch.tensor([[[0., 0., 0.],\n",
        "                    [0., 0., 0.],\n",
        "                    [0., 0., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., 1., 0.],\n",
        "                    [0., -1., 0.]],\n",
        "                    [[0., 0., 0.],\n",
        "                    [0., 0., 0.],\n",
        "                    [0., 0., 0.]]]).view(1,1,3,3,3).cuda()\n",
        "\n",
        "\n",
        "    D_star = torch.concatenate([Dh_star, Dp_star, Dv_star], dim=1)\n",
        "\n",
        "    tau = 0.1/(reg_par)\n",
        "\n",
        "    # parameters for backtracking linesearch\n",
        "    epsilon = 1e-9\n",
        "    delta = epsilon + 1e-6\n",
        "    gamma = 1e-5\n",
        "    eta = 0.9\n",
        "    i=0\n",
        "    xprec = x\n",
        "\n",
        "\n",
        "    while i <nit_fb and delta > epsilon:\n",
        "\n",
        "        xprec = x\n",
        "        backtracking_check = True\n",
        "        sub_counter = 0\n",
        "\n",
        "\n",
        "        while backtracking_check:\n",
        "\n",
        "            u = x - (tau*reg_par*postprocess_data(F.conv3d(F.conv3d(preprocess_data(x, tensorFlag=True), D, padding=1), D_star, padding=1), tensorFlag=True))\n",
        "            # xprox=torch.swapaxes(u,2,0)\n",
        "            xprox = u\n",
        "            x=GPUBiographProxRecons(BiographReconsParams=BiographParams,xprox=xprox,pnlt_beta=1.0/tau,dict_sino=dict_sino, tensor_output = True).squeeze()\n",
        "\n",
        "            lk = GPU_log_likelihood(x, eps =0, BiographParams=BiographParams,dict_sino=dict_sino)\n",
        "            # x=torch.swapaxes(x,2,0)\n",
        "\n",
        "            gx = reg_par*0.5*torch.norm(F.conv3d(preprocess_data(x, tensorFlag=True), D, padding=1))**2\n",
        "\n",
        "            if sub_counter > 0:\n",
        "                lossprec = loss\n",
        "            if i== 0 and sub_counter == 0:\n",
        "                linit = lk\n",
        "\n",
        "            loss = -lk + lbd*gx\n",
        "\n",
        "            ## Backtracking linesearch: If loss function is not increasing, we decrease tau\n",
        "            if (sub_counter == 0 or torch.abs(lossprec -loss) < (gamma/tau)*torch.norm(xprec-x)**2) :\n",
        "                # continue backtracking\n",
        "                tau = eta*tau\n",
        "                x = xprec\n",
        "                backtracking_check = True\n",
        "            else:\n",
        "                # move on to next iteration\n",
        "                if sub_counter > 0 and i > 0:\n",
        "                    delta  = torch.abs((lossprec-loss)/linit)\n",
        "                backtracking_check = False\n",
        "\n",
        "\n",
        "            sub_counter += 1\n",
        "        i += 1\n",
        "\n",
        "\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCSGSj3jUtg3"
      },
      "outputs": [],
      "source": [
        "nit_fb = 20\n",
        "lbd = 0.0000002\n",
        "\n",
        "\n",
        "x_admm = fb(x0=ordose, nit_fb=nit_fb, reg_par=lbd, BiographParams=ParamsGPUEM, dict_sino=dict_sino)\n",
        "x_admm = x_admm.squeeze().cpu().detach().numpy()\n",
        "\n",
        "fig=PETLibs.utils.display3D_1cbar(x_admm,interpolation='none', perc=0.7, title='reconstruction with FB - TV -l2 regularization')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zneA3n79Utg3"
      },
      "source": [
        "Construct and load GSDenoiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V58NNPZ6Utg3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from DL_utils import MyDeepModel2\n",
        "\n",
        "\n",
        "class MyGSDenoiser(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyGSDenoiser, self).__init__()\n",
        "        self.base = MyDeepModel2()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        x = x.requires_grad_()\n",
        "        N = self.base.forward(x)\n",
        "        JN = torch.autograd.grad(N, x, grad_outputs=x - N, create_graph=True, only_inputs=True)[0]\n",
        "        Dg = x - N - JN\n",
        "        x_hat = x - Dg\n",
        "\n",
        "        x_hat = x_hat.detach()\n",
        "        x = x.detach()\n",
        "        N = N.detach()\n",
        "        JN = JN.detach()\n",
        "\n",
        "\n",
        "        return x_hat\n",
        "\n",
        "    def getN(self, x):\n",
        "        x = x.float()\n",
        "        # x = x.requires_grad_()\n",
        "        N = self.base.forward(x)\n",
        "        return N\n",
        "\n",
        "\n",
        "\n",
        "GSnet = MyGSDenoiser()\n",
        "GSnet = GSnet.cuda()\n",
        "\n",
        "\n",
        "filename = 'gsnet.ckpt'\n",
        "checkpoint = torch.load(filename)\n",
        "GSnet.load_state_dict(checkpoint['state_dict'], strict=True)\n",
        "GSnet.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMLu_KQCUtg3"
      },
      "source": [
        "Write the PnP version of the forward backward algorithm with GSnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDOeoh5pUtg4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def pnp_fb(x0, nit_fb, reg_par, BiographParams, dict_sino, net):\n",
        "\n",
        "    x=torch.tensor(np.zeros_like(x0), dtype=torch.float32,device=\"cuda\")\n",
        "\n",
        "\n",
        "\n",
        "    tau = 1.99/(reg_par)\n",
        "    epsilon = 1e-9\n",
        "    delta = epsilon + 1e-6\n",
        "    gamma = 1e-5\n",
        "    eta = 0.9\n",
        "    i=0\n",
        "    xprec = x\n",
        "\n",
        "\n",
        "    while i <nit_fb and delta > epsilon:\n",
        "        print(\"#########################################################\")\n",
        "        print(f\"i={i} over {nit_fb}\")\n",
        "        print(\"#########################################################\")\n",
        "\n",
        "        xprec = x\n",
        "        backtracking_check = False\n",
        "        sub_counter = 0\n",
        "\n",
        "\n",
        "        while not backtracking_check:\n",
        "            # print(\"#########################################################\")\n",
        "            # print(x.shape)\n",
        "            # print(preprocess_data(x, tensorFlag=True).shape)\n",
        "            # print(net(preprocess_data(x, tensorFlag=True)).shape)\n",
        "            u =  postprocess_data((tau*reg_par*net(preprocess_data(x, tensorFlag=True))),tensorFlag=True) + (1-reg_par*tau)*x\n",
        "            # print(u.shape)\n",
        "\n",
        "\n",
        "            xprox=u\n",
        "            x=GPUBiographProxRecons(BiographReconsParams=BiographParams,xprox=xprox,pnlt_beta=1.0/tau,dict_sino=dict_sino, tensor_output = True).squeeze()\n",
        "            # print(x.shape)\n",
        "\n",
        "            lk = GPU_log_likelihood(x, eps =0, BiographParams=BiographParams,dict_sino=dict_sino)\n",
        "            # x=torch.swapaxes(x,2,0).cpu()\n",
        "\n",
        "\n",
        "            ## compute regularization\n",
        "            Nx = postprocess_data(net.getN(preprocess_data(x,tensorFlag=True)),tensorFlag=True)\n",
        "            gx = 0.5*torch.sum((x - Nx).flatten() ** 2).item()\n",
        "\n",
        "            if sub_counter > 0:\n",
        "                lossprec = loss\n",
        "            if i== 0 and sub_counter == 0:\n",
        "                linit = lk\n",
        "\n",
        "            loss = -lk + gx\n",
        "\n",
        "\n",
        "            ## Update parameters\n",
        "            if (sub_counter > 0 and np.abs(lossprec -lk) < (gamma/tau)*torch.norm(xprec-x)**2) :\n",
        "                tau = eta*tau\n",
        "                x = xprec\n",
        "                backtracking_check = False\n",
        "            else:\n",
        "                if sub_counter > 0 and i > 0:\n",
        "                    delta  = np.abs((lossprec-lk)/linit)\n",
        "                backtracking_check = True\n",
        "\n",
        "\n",
        "            sub_counter += 1\n",
        "            i += 1\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsB46gX1Utg4"
      },
      "source": [
        "Test PnP reconstruction with GSnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOHwjt7iUtg4"
      },
      "outputs": [],
      "source": [
        "nit_fb = 20\n",
        "lbd = 0.00002\n",
        "\n",
        "x_admm = pnp_fb(x0=ordose, nit_fb=nit_fb, reg_par=lbd, BiographParams=ParamsGPUEM, dict_sino=dict_sino, net=GSnet)\n",
        "x_admm = x_admm.squeeze().cpu().detach().numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0bsxgnrUtg5"
      },
      "outputs": [],
      "source": [
        "fig=PETLibs.utils.display3D_1cbar(x_admm,interpolation='none', perc=0.7, title='reconstruction with PnP FB')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py_marion_u22",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}